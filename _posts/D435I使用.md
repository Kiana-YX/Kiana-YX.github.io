# RealSense

## 联合操作

1. 像素赋值

   1. 注意事项

      坐标原点为**左上角**

      像素值范围**下限为0，上限为255**

   2. 单通道

      ```c++
      cv::Size smallSize;
      	smallSize.height = 100;
      	smallSize.width = 100;
      	cv::Mat Image = cv::Mat(smallSize, CV_8U, Scalar(0));// 创建单通道黑色图像。
      	for(int i =0;i<20;i++)
      	{
      		for(int j=50;j<80;j++)
      			Image.at<uchar>(j, i)=255;
      	}
      	cv::imshow("Test", Image);
      	cv::waitKey(0);
      	//销毁所有窗口
      	cv::destroyAllWindows();
      ```

   3. 三通道

      ```
      image.at<cv::Vec3b>(j,i)[channel]= value;
      or
      image.at<cv::Vec3b>(j,i) = cv::Vec3b(a,b,c);
      ```

      

   4. 。。

2. 。。

## 基本使用

1. 上位机

   ```
   realsense-viewer
   ```

2. [ROS接口使用:](http://zhaoxuhui.top/blog/2020/09/09/intel-realsense-d435i-installation-and-use.html)

   ```
   roslaunch realsense2_camera rs_camera.launch
   ```

   ![](https://gitee.com/Kiana-yx/pictures/raw/master/img/202201240923290.png)

   ![](https://gitee.com/Kiana-yx/pictures/raw/master/img/202201240925000.png)


3. 额，无法用rosbag
   [世纪谜团之谁的bug](https://github.com/IntelRealSense/realsense-ros/issues/797)

## 视觉小知识

1. 缩放图片

   ```python
   res = cv2.resize(img, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_AREA)
   
   res = cv2.resize(img, (400, 500), 0, 0, interpolation=cv2.INTER_CUBIC)
   
   height, width = img.shape[:2]
   res = cv2.resize(img, (width*2,height*2), interpolation=cv2.INTER_AREA)
   ```

2. 显示多个图片

   1. 使用pyplot

      ```python
      from matplotlib import pyplot as plt
      
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # OpenCV 和 matplotlib 中的颜色通道顺序不一样
      
      plt.subplot(131), plt.imshow(img, 'gray'), plt.title('WRAP')
      plt.subplot(132), plt.imshow(img2, 'gray'), plt.title('CONSTANT')
   plt.show()
      ```

   2. 使用numpy
   
      ```python
      import numpy as np
      
      fin = np.hstack((img, img2))
      cv2.namedWindow("first", 0)
      
      cv2.imshow('first', fin)
      key = cv2.waitKey(0)
      if key == 27:
          cv2.destroyAllWindows()
      ```
   
3. 滑动条+canny边缘检测

   ```
   import cv2
   
   # 载入图片
   img_original = cv2.imread('/home/kiana/Code/openCV_learning/img/blue.jpg')
   # 设置窗口
   cv2.namedWindow('Canny')
   
   
   # 定义回调函数
   def nothing(x):
       pass
   
   
   # 创建两个滑动条，分别控制threshold1，threshold2
   cv2.createTrackbar('threshold1', 'Canny', 50, 400, nothing)
   cv2.createTrackbar('threshold2', 'Canny', 100, 400, nothing)
   while 1:
       # 返回滑动条所在位置的值
       threshold1 = cv2.getTrackbarPos('threshold1', 'Canny')
       threshold2 = cv2.getTrackbarPos('threshold2', 'Canny')
       # Canny边缘检测
       img_edges = cv2.Canny(img_original, threshold1, threshold2)
       # 显示图片
       cv2.imshow('original', img_original)
       cv2.imshow('Canny', img_edges)
       if cv2.waitKey(1) == ord('q'):
           break
   cv2.destroyAllWindows()
   
   ```

4. 轮廓绘制

   **cv2.fifindContours()**，**cv2.drawContours()**

   轮廓可以简单认为成将**连续的点（连着边界）**连在一起的曲线，具有相同的颜色或者灰度。

## 深度学习

随着计算机视觉的流行，opencv也专门开发了**dnn模块**来实现深度神经网络相关的功能；

虽然opencv无法训练模型，但它支持载入其他深度学习框架训练好的模型，并使用该模型进行预测inference；

故如果想在opencv中融入深度学习模型，可以先使用深度学习框架训练好模型，再使用dnn模块载入

调用realsense实现目标检测：

```python
import cv2
import pyrealsense2 as rs
import numpy as np

# Configure depth and color streams
pipeline = rs.pipeline()
config = rs.config()

# Get device product line for setting a supporting resolution
pipeline_wrapper = rs.pipeline_wrapper(pipeline)
pipeline_profile = config.resolve(pipeline_wrapper)
device = pipeline_profile.get_device()
device_product_line = str(device.get_info(rs.camera_info.product_line))

config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

# Start streaming
pipeline.start(config)

face_cascade = cv2.CascadeClassifier(
    '/home/kiana/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/data/haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(
    '/home/kiana/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/data/haarcascade_eye.xml')

try:
    while True:
        frames = pipeline.wait_for_frames()

        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()

        # Convert images to numpy arrays 把图像转换为numpy data
        depth_image = np.asanyarray(depth_frame.get_data())
        color_image = np.asanyarray(color_frame.get_data())

        gray = cv2.cvtColor(color_image, cv2.COLOR_RGB2GRAY)

        faces = face_cascade.detectMultiScale(gray, 1.1, 5, cv2.CASCADE_SCALE_IMAGE, (10, 10), (200, 200))
        for (x, y, w, h) in faces:
            img = cv2.rectangle(color_image, (x, y), (x + w, y + h), (255, 0, 0), 2)
            # roi_gray = gray[y:y + h, x:x + w]
            # roi_color = img[y:y + h, x:x + w]
            # eyes = eye_cascade.detectMultiScale(roi_gray)
            # for (ex, ey, ew, eh) in eyes:
            #     cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)

        # 显示图像
        # Show images
        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)
        cv2.imshow('RealSense', color_image)
        k = cv2.waitKey(5) & 0xFF
        if k == 27:
            break
finally:

    # Stop streaming
    pipeline.stop()

```

1. 目标检测与目标分类

   图像分类是生成**单个输出**，即类别概率分布

   ![](https://gitee.com/Kiana-yx/pictures/raw/master/img/202201311657246.png)

   目标检测模型将通过预测**每个物体**的边界框来给出各个物体的位置，计算损失函数就需要匹配真实框（ground-truth bounding box）与预测框。

   <img src="https://gitee.com/Kiana-yx/pictures/raw/master/img/202201311657520.png" style="zoom:67%;" />

2. one-stage目标检测算法

   one-stage检测方法，仅仅需要送入网络一次就可以预测出所有的边界框，因而速度较快，非常适合移动端。最典型的one-stage检测算法包括YOLO，SSD，SqueezeDet以及DetectNet。
   
   
   
   

## 辅助工具

1. [网络可视化工具](https://blog.csdn.net/nan355655600/article/details/106245563)
